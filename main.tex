\documentclass[a4paper,11pt,oneside,openany]{jsbook}
\usepackage{graphicx,enumerate}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{longtable}
\usepackage{supertabular}
\usepackage{subfigure}
\usepackage{lscape}

% declaration of the new block
\algblock{ParallelForByBlocks}{EndParallelForByBlocks}
% customising the new block
\algnewcommand\algorithmicparallelforbyblocks{\textbf{parallelForByBlocks}}
\algnewcommand\algorithmicpardo{\textbf{do}}
\algnewcommand\algorithmicendparallelforbyblocks{\textbf{end\ parallelForByBlocks}}
\algrenewtext{ParallelForByBlocks}[1]{\algorithmicparallelforbyblocks\ #1\ \algorithmicpardo}
\algrenewtext{EndParallelForByBlocks}{\algorithmicendparallelforbyblocks}

\pagestyle{plain}
\setlength{\textwidth}{\fullwidth}
\setlength{\evensidemargin}{\oddsidemargin}
\def\vector#1{\mbox{\boldmath $#1$}}
\begin{document}
\thispagestyle{empty}
%------------------------------標題紙作成エリア----------------------------%
2017年度　修士学位論文%1
\bigskip%2
\LARGE%3
\begin{center}
修士学位論文
\end{center}
\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip %7
\begin{center} %8
PDBを用いたGPU上の並列IDA*探索
\end{center}
\large %11
\begin{center}
Parallel IDA* search using PDB for GPUs 
\end{center}
\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
\Large %17
\begin{center}
広域システム科学系　広域科学専攻
\end{center}
\Large %17
\begin{center}
指導教員:　福永 アレックス
\end{center}
\LARGE %21
\begin{center}
山村　武史
\end{center}
\normalsize
%---------------------------------目次エリア-------------------------------%
\thispagestyle{empty}
\setcounter{tocdepth}{3}
\tableofcontents
%---------------------------------本文エリア-------------------------------%

\chapter{序論}
\section{研究の概要}
本研究では、ヒューリスティック探索の一つであるIDA*探索\cite{Kor85}をGPUを利用した並列化手法についての研究に取り組んだ。
IDA*探索についてGPUを利用した高速な並列アルゴリズムのひとつにBPIDA*探索\cite{HA17}がある。この手法では、IDA*探索を一つのブロックに対してノードを一つ割り当て、このノードを根とするf値制限深さ優先探索を行うことで、warp divergenceを隠蔽し、高速な並列化を行った。これによって直列実行時と比べて5倍ほどのスピードアップに成功している。

堀江らの研究\cite{HA17}におけるBPIDA*探索では、ヒューリスティック関数としてマンハッタン距離を使用し、これを共有メモリにおいて使用していた。共有メモリは、GPUカーネル側に置くことのできるオンチップメモリであり、カーネル側から高速にアクセスすることができる一方、そのメモリ容量は、64Kbyteと比較的小さい。

ヒューリスティック探索の探索性能は、ヒューリスティック関数の精度に依存する。N-puzzle問題における、ヒューリスティック関数のうちマンハッタン距離より精度の高いものとして、パターンデータベースがあげられる。パターンデータベースは例えば$N=24$の時のN-puzzle問題では、250Mbyteほどの容量を必要とし、マンハッタン距離に比べ、かなり多くのメモリを使用する必要がある。共有メモリが64Kbyteの記憶領域をL1キャッシュと共有していることを考慮すると、パターンデータベースをBPIDA*探索で使用するには、当然より大きなメモリ領域を使用しなければならない。
本研究では、パターンデータベースを共有メモリよりも、容量が大きく、低速なグローバルメモリに置いたBPIDA*探索と、従来の共有メモリにマンハッタン距離をおいたBPIDA*探索で、スピードアップの比較を行った。これにより、共有メモリではなくグローバルメモリを使用することによる遅延がBPIDA*探索の探索時間にどのような変化をしめすのか検証した。

またこの検証結果を踏まえ、共有メモリに異なる大きさの記憶領域を確保した際に、探索効率がどのように変わるのか、より詳細な検証を行った。

% \section{本研究の目的}
% 本研究の目的はぶらぶらぶら
% \begin{enumerate}
% \item ぶらぶら
% \vspace{3mm}
% \newline
% ぶらぶらぶらぶらぶら
% \newline

% \item ぶらぶらぶら
% \vspace{3mm}
% \newline
% ぶらぶらぶらぶら
% \end{enumerate}


\section{本論文の構成}
本論文は以下の通りに構成される。

2章で、本研究の背景としてGPUおよび、GPU上でのプログラミングに必要なプラットフォームであるCUDAについての説明を行った後、本研究で取り扱うグラフ探索問題について問題の定義と、それを取り扱う古典的なアルゴリズムについて説明する。

3章では、本研究と関連した先行研究について紹介するとともに、ベースラインとなる直列環境および並列環境における、先行研究の再現実験について紹介する。

4章では、グローバルメモリにPattern Databaseをおいた直列環境および並列環境におけるIDA*探索の実験について紹介する。

5章では、4章での知見をふまえ、共有メモリが大きな領域を確保した際にBPIDA*探索がどのような影響をうけるか、その検証結果を紹介する。

6章では、本研究における知見をまとめる。

\chapter{導入}
% \chapter{GPUとグラフ探索アルゴリズム}
\section{GPU}
\subsection{GPUとCUDA}
GPU(graphics processing unit)は2Dや3Dといったコンピューターグラフィックスの画像処理を行う為に従来使用され、それらの性能を向上することを追求してきた。
GPUをグラフィックスのレンダリングのみならず、より汎用的な計算にも利用することを目的とした技術がGPGPU(General-purpose computing on graphics processing units)である。
GPGPUが使われる分野として、物理シミュレーション、機械学習、音声処理、金融工学などのアプリケーションがあげられる。現在、機械学習への注目が高まるとともに、その需要が高まっている。

CUDA(Compute Unified Device Architecture)とはNVIDIA社が提供するGPGPUのための統合開発環境である。GPUの並列コンピュートエンジンを利用して多くの複雑なコンピューティング問題をより効率的に解決する。CUDAではC、C++、Fortranなどの言語で開発が可能である。
% 本節では、GPUを利用したCUDAプログラミングにおけ、およびメモリモデルについて説明する。

\subsection{CUDAプログラミングの構造}
CUDAプログラミングモデルでは、CPUとそれを補完するGPUの両方を使用したヘテロジニアスコンピューティングを行うことができる。CPUとそのメモリを{\bf ホスト}、GPUとそのメモリを{\bf デバイス}と呼び、デバイス側で実行されるコードのことをカーネルと呼ぶ。ホスト側からカーネル関数を呼ぶことでGPU上での処理をCPUと非同期的に行うことができる。

またCUDAで並列計算を行う際の実行単位は、スレッド、ブロック、グリッドと呼ばれる三つの階層に分けることができる。

スレッドはカーネルを動作させた時のプログラムの最小単位である。CPUではコア数と同数のスレッドしか動作できないのに対し、GPUではコアに対し数千～数万といった数のスレッドを並列に動作できるのが強みである。

ブロックはスレッドの集まりであり、同一ブロック内のスレッド同士での同期、共有メモリによるデータの共有が可能である。一つのブロックに最大512スレッド格納することができ、x方向、y方向、z方向の三次元で、スレッドの配置を指定することができる。

グリッドはブロックの集まりであり、ブロック同様x方向、y方向、z方向の三次元で、ブロックの配置を指定することができる。x方向、y方向に配置できる最大ブロック数は、それぞれ65535個であり、これ以上のブロックを配置することはできない。

CUDAはSIMT(SIngle Instruction Multiple Thread)アーキテクチャを採用しており、スレッドが32個ずつのワープと呼ばれるグループにまとめられ、ワープ内のスレッドは全て同じ命令を同時に実行する。同一ワープ内のスレッドがif文による分岐などで異なる命令を実行することを{\bf ワープダイバージェンス}と呼ぶ。ワープ内のスレッドが異なる分岐パスを選択する場合、各分岐パスを逐次的に実行し、そのパスを通らないスレッドは無効化される。これによってパフォーマンスが大幅に低下する可能性があり、ワープ内の分岐をできる限り揃えることがパフォーマンス向上に不可欠となる。

またローカルなメモリやキャッシュメモリ、レジスタ、演算装置、ワープスケジューラなどの計算資源の集まりをSM(Streaming Multiprocessor)と呼ぶ。SMにはスレッドブロックが割り当てられ、それをさらに32個のワープに分割し、利用可能なハードウェアリソースを割り当てる。

\subsection{メモリモデル}
プログラミングを行う上でメモリは一般的に、プラグラマー側が明示的に制御可能なプログラマブルなメモリと、データの配置を制御することが不可能なノンプログラマブルなメモリの二つに分類される。CUDAのメモリモデルでは、レジスタ、共有メモリ、ローカルメモリ、コンスタントメモリ、テクスチャメモリ、グローバルメモリの6種類が制御可能なプログラマブルメモリであり、GPUのキャッシュであるL1キャッシュ、L2キャッシュ、コンスタントキャッシュ、テクスチャキャッシュの4種類がノンプログラマブルなメモリである。

またCUDAにおけるメモリはさらにGPUの内部に存在するオンチップメモリと、オフチップメモリに分かれる。
オンチップメモリには高速なアクセスが可能であが、容量が小さい。一方、オフチップメモリではアクセスは低速だが、その容量は大きいという特徴がある。
ここでは、本論文において重要な意味をもつグローバルメモリ、共有メモリ、L1キャッシュ、レジスタについて詳しく説明する。

グローバルメモリは、オフチップメモリの一つで、GPUにおいて最も容量が大きく、最も遅延が大きいメモリである。グローバルメモリでは、すべてのスレッド、ホストから読み書きが可能であり、SMの外部に用意されている。

共有メモリは、オンチップメモリの一つで、一つのブロック内の全てのスレッドが共有する記憶領域であり、グローバルメモリと比べて、GPU側からの高速な読み書きが可能となっている。一方その容量は比較的小さく、一つのブロックあたり、L1キャッシュと共有した64Kbyteの領域しか確保できない。

L1キャッシュはノンプログラマブルメモリの一つで、ローカルメモリとグローバルメモリにアクセス時のデータをキャッシュするために使用される。そのメモリ容量は共有メモリと64Kbyteのメモリ領域を共有する。

レジスタはGPUにおいて最も高速なオンチップメモリであり、カーネルで宣言される自動変数は通常レジスタに登録される。レジスタの数がハードウェア制限を超える場合、超えた分のレジスタはローカルメモリに退避される。このような現象をレジスタピルと呼び、パフォーマンスに悪影響を及ぼす可能性がある。レジスタピルが起きた際、ローカルメモリからのロードは、L1キャッシュに保存されることがあるため、カーネルが使用するレジスタの数が多い場合、L1キャッシュの量を増やすと効果的である。

CUDAプログラミングモデルにおいて、これらのメモリ領域の容量、レイテンシの大小やスコープを意識したアルゴリズムを実装することが、性能を引き出す上で重要である。

% \section{CUDA}
% CUDA(Compute Unified Device Architecture)とはNVIDIA社が提供するGPUコンピューティングのための統合開発環境である。。GPUの並列コンピュートエンジンを利用して多くの複雑なコンピューティング問題をより効率的に解決する。CUDAではC、C++、Fortranなどの言語で開発が可能である。本節ではCUDAプログラミングにおける

% \subsection{GPUのメモリ構造}
% GPUの大きな特徴の一つとしてCPUとは、異なるメモリ構造があげられる。GPUのデバイス側で使われるメモリは大きくGPU側のオンチップメモリと、CPU側のオフチップメモリの2つに別れる。オンチップメモリの方が、カーネル側からは高速なアクセスが可能である一方、そのサイズは小さくなる。大容量であるメモリのほとんどは、CPU側のオンチップメモリに存在し、容量と引き換えに、高遅延となっている。
% 変数のスコープやライフタイムについても、それぞれのメモリで異なり、これらの特徴をまとめると、以下の図のようになっている。GPUを使用したプログラミングでは、これらのメモリの特徴を踏まえた上で、適したメモリを選択することが、高速化の肝となる。
% 特にグローバルメモリと共有メモリについては本論文において重要な役割を果たすため、紹介する。
% グローバルメモリはCPU上において最も容量が大きい一方で遅延が最も大きいメモリである。すべてのスレッドとホストの両方から読み書きが可能である。
% それに対して、共有メモリはオンチップメモリの一つであり、同じブロック同士でのみスコープを共有する。


% \subsection{CUDA}
% CUDA(Compute Unified Device Architecture)とはNVIDIA社が提供する汎用的な並列コンピューティングプラットフォームとAPIを含む、プログラミングモデルであり、NVIDIAによって開発された。GPUの並列コンピュートエンジンを利用して多くの複雑なコンピューティング問題をより効率的に解決する。CUDAではC、C++、Fortranなどの言語で開発が可能であり、
% CUDAではCPUとそのメモリを扱うホストと、GPUとそのメモリを扱うデバイスの二つにわかれている、ヘテロジニアスアーキテクチャである。

% \subsection{実行単位}
% CUDAプログラミングの特徴の一つとして
% \begin{enumerate}
% \item　ホスト
% \vspace{3mm}
% \newline
% ぶらぶらぶらぶらぶら
% \newline

% \item　デバイス
% \vspace{3mm}
% \newline
% ぶらぶらぶらぶら
% \end{enumerate}

% \newpage
\section{グラフ探索アルゴリズム}
\subsection{グラフ探索問題}
グラフ$G$とはノードの集合$V$と、そのノード同士を結ぶの集合$E$からなり、そのようなグラフを$G=(V,E)$と表す。
$e \in E$は2つのノード$v \in V$の列$e = (v_{1}, v_{2})$で表される。
ある$e \in E$に対して$e = (v_{1}, v_{2})$と$e = (v_{2}, v_{1})$を区別しない場合、そのようなグラフを無向グラフと呼び、一方区別する場合、有向グラフと呼ぶ。
また、それぞれの辺$e = (v_{1}, v_{2})$はコスト$c$を持つ。

グラフ探索問題の入力は、このグラフ$G=(V,E)$と、初期ノード$v_0$とゴールノード$v_g$である。それに対し、出力は、初期ノード$v_0$からゴールノード$v_g$へ至るまでの経路、つまり辺の列$\langle(v_{1}, v_{2}), (v_{2}, v_{3}), ...,(v_{k-1}, v_{g}) \rangle$である。

本節では、このグラフ探索問題を解くことのできる古典的なアルゴリズムについていくつか紹介する。

\subsection{A*探索}
A*探索\cite{HNR68}はヒューリスティック関数と呼ばれる、ある状態からゴール状態までの見積もりを道しるべに使用したグラフ探索の手法の一つである。
% 状態$v$について、初期状態から現在までの移動コスト$g(v)$と、現在から終了状態までのコストの見積もり値$h(v)$の合計$f(v) = g(v) + h(v)$が小さなノードから順に探索を行うことで、ゴール状態までの経路を効率良く探索することができる。

A*探索では、すでに展開され、再び展開する必要のないノードをクローズドリスト、これから展開する必要のあるノードをオープンリストに保存する。一度評価した状態および、未展開の状態を全て記録するため、重複展開を避けることができる。

オープンリストはプライオリティーキューと成っており、状態の評価値$f(v)$が小さなノードから順に展開される。状態の評価値$f(v)$は初期状態から現在までの移動コスト$g(v)$と、現在から終了状態までのコストの見積もり値$h(v)$の和$f(v) = g(v) + h(v)$で決定される。

$h(v)$はヒューリスティック関数によって計算される。$h(v)$が、実際のある状態から、ゴール状態に至るまでの最短移動コスト以下であるとき、このようなヒューリスティック関数をadmissibleであると呼ぶ。

admissibleなヒューリスティック関数を使用した場合、A*探索では必ず最短経路を発見することが保証される。
また本研究で使用するManhattan DistanceやPattern Data Baseはこのadmissibleなヒューリスティックである。

A*探索の探索効率は、このヒューリスティック関数に依存し、ヒューリスティック関数が常に正しい値を返すことができる場合、分岐をすることなく最短経路を発見することができる。このようなヒューリスティクスをパーフェクトヒューリスティクスと呼ぶ。
またヒューリスティック値$h(v)$が常に0である場合、A*探索はダイクストラ探索と同じアルゴリズムとなる。
A*探索は適切なヒューリスティック関数を用いることでダイクストラ法よりも効率良く、最短経路問題を解くことが可能である。

A*探索の問題点として、メモリ使用量の大きさがあげられる。答えとなる最短経路の深さを$d$、各ノードを展開した際の子ノードの平均の数$b$(branching factor)とした時のA*探索の空間計算量は$O(b^d)$となる。これは探索で生成した全ての状態をメモリに保存するため、指数的に大きなメモリが必要となるからである。
このような問題点を解決する手法として、後述のIDA*探索\cite{Kor85}、メモリが不足するとf値の大きなノードをオープンリストから消去して探索を行うSMA*探索\cite{Rus92}などがある。


% \newpage
\begin{algorithm}
\caption{A*探索}
\label{alg:pbnf}
\begin{algorithmic}[1]
\State $openList$を見積もり値$f(v)$を優先度としたプライオリティーキューとして定義
\State 初期ノード$v_0$を$openList$に追加。
\State $closedList$をハッシュテーブルとして定義
\While {$openList$が空ではない}
    \State $v_{cur}$ $\leftarrow$ $openList$の中で $f(v)$が最も小さいノード
    \State $openList$から$v_{cur}$を削除
    \If {$v_{cur} \in 終了状態$}
        \State $v_0$から$v_{cur}$までの遷移と、移動コスト$g(v_{cur})$を解として出力して終了
    \EndIf
    \State $closedList$に$v_{cur}$を追加
    \For{each $v_{next}$ $\in$ $children(v_{cur})$ do}
        \State $f_{new}(v_{next}) \leftarrow g(v_{cur}) + cost(v_{cur}, v_{next}) + h(v_{next})$
        \If {$v_{next}\not\in openList \land v_{next}\not\in closedList$}
            \State $f(v_{next}) \leftarrow f_{new}(v_{next})$ 
            \State $openList$に$v_{next}$を追加
            \State $v_{next}$の親を$v_{cur}$として記録
        \EndIf
        \If {$v_{next}\in openList \land f_{new}(v_{next}) < f(v_{next})$}
            \State $f(v_{next}) \leftarrow f_{new}(v_{next})$
            \State $openList$から$v_{next}$を削除し、再び$v_{next}$を追加することで、優先度を更新
            \State $v_{next}$の親を$v_{cur}$として記録
        \EndIf
        \If {$v_{next}\in closedList \land f_{new}(v_{next}) < f(v_{next})$}
            \State $f(v_{next}) \leftarrow f_{new}(v_{next})$
            \State $closedList$から$openList$に$v_{next}$を移動
            \State $v_{next}$の親を$v_{cur}$として記録
        \EndIf
    \EndFor
\EndWhile
\State 初期状態から終了状態までのパスは存在しないと出力して終了
\end{algorithmic}
\end{algorithm}
\newpage

\subsection{IDA*探索}
IDA*探索\cite{Kor85}はKorfによって提案された手法であり、そのアルゴリズムは反復深化深さ優先探索(IDDFS)にA*探索を応用したものである。

IDDFSでは深さを制限した深さ制限深さ優先探索を繰り返すことによって最短経路を求めることができる。IDA*探索は、この深さ制限深さ優先探索を行う代わりに、ヒューリスティック関数を用いたゴールまでの下限値$h(v)$と、その状態までの深さ$g(v)$の和$f(v) = g(v) + h(v)$によるf値制限深さ優先探索を行う。f値制限深さ優先探索のf値を徐々に大きくしながら繰り返すことでゴール状態までの経路を発見することができる。仮に$h(v)$が常に0である時、IDA*探索はIDDFSと同義になる。
またA*探索同様、admissibleなヒューリスティック関数を用いることで、最初に発見した経路が最短経路であることが保証される。

IDA*探索の特徴として、メモリ使用量があげられる。空間計算量は答えとなる最短経路の深さを$d$、各ノードを展開した際の子ノードの平均の数$b$(branching factor)とした時、A*探索では、$O(b^d)$であったのに対し、IDA*探索では$O(bd)$となる。
これはA*探索が全ての探索済みの状態を保持したまま探索を進めていたのに対し、IDA*探索では、クローズドリストを用いず、重複展開を許容するためである。よってIDA*探索では、探索の深さに対して線形を保つことができ、A*探索ではメモリ不足で解けない問題においても解を発見することが可能である。
一方、IDA*探索の欠点として、何度も同じ状態を展開するために、A*探索と比べて無駄な探索を行うことになってしまう。

\begin{algorithm}
\caption{IDA*探索}
\label{alg:pbnf}
\begin{algorithmic}[1]
\State $limit_f \leftarrow 0$
\While {true}
    \State $openList$を空のスタックとして初期化
    \State 初期ノード$v_0$を$openList$に追加
    \State $f_{next} \leftarrow \infty$
    \State $f_{next}$は次回の$limit_f$更新時に利用される 
    \While {$openList$が空ではない}
        \State $v_{cur}$ $\leftarrow$ $openList$から先頭ノードを取り出す
        \State $openList$から$v_{cur}$を削除
        \If {$v_{cur} \in 終了状態$}
            \State $v_0$から$v_{cur}$までの遷移と、移動コスト$g(v_{cur})$を解として出力して終了
        \EndIf
        \For{each $v_{next}$ $\in$ $children(v_{cur})$ do}
            \State $f_{new} \leftarrow g(v_{cur}) + cost(v_{cur}, v_{next}) + h(v_{next})$
            \If {$f_{new}(v_{next}) \leqq limit_f$}
                \State $openList$に$v_{next}$を追加
            \Else
                \State $f_{next} \leftarrow min(f_{next}, f_{new})$
            \EndIf
        \EndFor
    \EndWhile
    \State $update(limit_f)$
\EndWhile
\end{algorithmic}
\end{algorithm}
\newpage



% \chapter{GPUを使用した並列IDA*探索の}
\chapter{先行研究におけるGPUを使用した並列IDA*探索とその再現}
\section{先行研究}
% \subseciton{B}
% \section{PSimple}

\subsection{Block Parallel IDA*}
GPUを使用したIDA*探索の並列化の一つにBlock-Parallel IDA*(BPIDA*)\cite{Horie17}がある。この手法では、同じBlockが1つのスタックを共有することでblock並列化を行っている。一つのスタックを共有するため、スタックからノードを取り出す、および追加する操作はそれぞれ、並列に行わなければならない。特にスタックにノードを追加する操作、AtomicPutでは、スタックにロックをかけ、原子性を保ちながら行う。

同一ブロック内の全てのスレッドが共有する一つのスタックが$sharedOpenList$である。このスタックには二つの並列な操作、$parallelPop$と$atomicPut$を行う。$parallelPop$では、sharedOpenListから1ブロック内のスレッド数を行為の数で割った数だけのノードを一度に取り出す。$atomicPut$では$v_{next}$を$sharedOpenList$に同時に挿入する。この操作を行う際には、挿入をする前に$sharedOpenList$にロックをかけ、挿入後そのロックを外すことで原子性をたもつ。
BPDFS関数は標準的なf値制限深さ優先探索とにている。


\newpage
\begin{algorithm}
\caption{Block Parallel IDA*}
\label{alg:pbnf}
\begin{algorithmic}[1]
\Function{BPDFS}{$root, goals, limit_f$}
    \State $sharedOpenList$を空のスタックとして初期化し共有メモリにおく
    \State 初期ノード$root$を$sharedOpenList$に追加
    \State $f_{next} \leftarrow \infty$
    \State $f_{next}$は次回の$limit_f$更新時に利用される 
    \While {$sharedOpenList$が空ではない}
        \State $v_{cur}$ $\leftarrow$ ${ParallelPop}(sharedOpenList)$
        \If {$v_{cur} \in goals$}
            \State $root$から$v_{cur}$までの遷移と、移動コスト$g(v_{cur})$を解として出力して終了
        \EndIf
        \State $v_{next} \gets $$v_{cur}$を($threadId$を行為数で割った余り)番目の行為で遷移した時の状態
        \State $f_{new} \leftarrow g(v_{cur}) + cost(v_{cur}, v_{next}) + h(v_{next})$
        \If {$f_{new}(v_{next}) \leqq limit_f$}
            \State ${AtomicPut}(sharedOpenList, v_{next})$ \Comment{sharedOpenListに$v_{next}$を原子性を保ちつつ追加}
        \Else
            \State $f_{next} \leftarrow min(f_{next}, f_{new})$
        \EndIf
    \EndWhile
    \State $update(limit_f)$

    \State \Return $a$
\EndFunction
\Function{BPIDA*}{$start, goals$}
    \State $rootSet \gets {CreateRootSet}(start, goals)$
    \State $limit_f \leftarrow {DecideFirstLimit}(rootSet)$
    \While {最短距離が発見されるまで}
        \ParallelForByBlocks{$each root \in rootSet do$}
            \State $limit_f, stat \gets {BPDFS}(root, goals, limit_f)$
        \EndParallelForByBlocks
        \State $UpdateRootSet(rootSet, stat)$
    \EndWhile
\EndFunction

\end{algorithmic}
\end{algorithm}
\newpage

\section{IDA*探索の直列実行の性能評価}
本研究では、N-puzzle問題を使用したIDA*探索のソルバを作成した。並列処理であるBPIDA*の再現を行う前に、そのベースラインとなる直列実行での、IDA*探索を

\subsection{siliding puzzle}
sliding puzzleとはケースの中に収められたブロックをスペースに隣接するブロックを動かすことで、任意の配置から目的の配置を目指すパズルである。特に$k * k$の正方形の中に、$ k * k - 1$枚のブロックと一つのスペースが存在するようなsliding puzzleをN-puzzleと呼ぶ。可能な遷移の数はスペースの配置によって決まり、$2~4$である。
N-puzzle問題は、Nが増えるにつれてその探索空間は大きくなり、$N=15$のときで、最長手数が80手ほどとなる。またヒューリスティック関数として、マンハッタン距離やPattern Databseなどがあり、問題の性質などが十分研究されている。また先行研究である、GPUにおけるIDA*探索のBlock並列化\cite{HA17}においてもこの問題が用いられているため、比較が容易である。よって本論文では性能評価のためN-puzzle問題を用いた。

\subsection{実験の設定}


\subsection{比較対象となる実装}
Horieらの研究\cite{HA17}では、Burnsらの研究\cite{BHLR12}をもとに15-puzzleのCPUを用いた直列IDA*探索の実装を行っている。このソルバは、様々な最適化を施したBurnsらの直列IDA*探索の実装よりも1.31倍ほど高速なソルバであり、現在入手可能な実装のうち、最も効率的な直列IDA*探索の一つである。なおこのソルバはグラフ探索問題において最短経路となる解を一つのみ発見するソルバである。このソルバで採用されている最適化の一つに、問題集に対して最も実行時間の早くなる順に頂点を展開するというものがある。しかしながらこれは、本来事前にはわからない問題集の情報をもとによる最適化である。よってこのソルバを最短経路となる解を全て発見するソルバに拡張を行った。このソルバをソルバHとし、以降、本研究で比較対象となるソルバは全て、最短経路となる解を全て発見するグラフ探索問題に拡張をしたものとする。

またHorieらの研究で実装されたBPIDA*探索のソルバをソルバBPIDA*(origin)とする。

自身の研究のベースラインとして、直列実行のIDA*探索のソルバ、Horieらの研究\cite{HA17}で提案されたPsimpleおよび、BPIDA*探索のソルバを作成した。Psimpleは並列IDA*探索の素朴な実装であり、プログラム開始時に根集合を一度だけ作成し、各スレッドに根集合から一つずつ根を割り当ててf値制限深さ優先探索を行う。このとき静的なロードバーランスや動的なロードバランスを何も行わないといったものである。




\chapter{PDBをグローバルメモリにおいたBPIDA*探索の実装と評価}

\chapter{ぶらぶら}





\begin{table}[]
\centering
\caption{Table 1: Total Runtimes for 50 24-Puzzle Instances}
\label{my-label}
\begin{tabular}{|l|c|}
\hline
configuration & \multicolumn{1}{l|}{total runtime(seconds)} \\ \hline
\multicolumn{2}{|l|}{CPU-based sequential algorithms} \\ \hline
IDA* (manhattan distance) & 743.019 \\
IDA* (PDB) & 1.4446 \\ \hline
\multicolumn{2}{|l|}{GPU-based parallel algorithms} \\ \hline
PSimple (manhattan distance) & 2106.27 \\
PSimple (PDB) & 4.91605 \\
BPIDA* (manhattan distance) & 674.521 \\
BPIDA* (PDB) & 0.994512 \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Table 1: Total Runtimes for 50 24-Puzzle Instances}
\label{my-label}
\begin{tabular}{|l|c|}
\hline
configuration & \multicolumn{1}{l|}{total runtime(seconds)} \\ \hline
\multicolumn{2}{|l|}{CPU-based sequential algorithms} \\ \hline
IDA* (manhattan distance) & 743.019 \\
IDA* (PDB) & 1.4446 \\ \hline
\multicolumn{2}{|l|}{GPU-based parallel algorithms} \\ \hline
PSimple (manhattan distance) & 2106.27 \\
PSimple (PDB) & 4.91605 \\
BPIDA* (manhattan distance) & 674.521 \\
BPIDA*GLOBAL (manhattan distance) & 124.586 \\
BPIDA* (PDB) & 0.994512 \\
BPIDA*GLOBAL (PDB) & 0.401973 \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Table 1: Total Runtimes for 50 24-Puzzle Instances}
\label{my-label}
\begin{tabular}{|l|c|}
\hline
configuration & \multicolumn{1}{l|}{total runtime(seconds)} \\ \hline
\multicolumn{2}{|l|}{CPU-based sequential algorithms} \\ \hline
IDA* (manhattan distance) & 743.019 \\
IDA* (PDB) & 1.4446 \\ \hline
\multicolumn{2}{|l|}{GPU-based parallel algorithms} \\ \hline
PSimple (manhattan distance) & 2106.27 \\
PSimple (PDB) & 4.91605 \\
BPIDA* (manhattan distance) & 674.521 \\
BPIDA*GLOBAL (manhattan distance) & 124.586 \\
BPIDA* (PDB) & 0.994512 \\
BPIDA*GLOBAL (PDB) & 0.401973 \\ \hline
\end{tabular}
\end{table}

\chapter{終わりに}
\section{まとめ}



%-----------------------------参考文献記述エリア---------------------------%
\begin{thebibliography}{10}
  \bibitem{HA17} Satoru Horie and Alex Fukunaga. Block-Parallel IDA* for GPUs. In SOCS, 2017 
  \bibitem{Burns et al. 2012} Burns, E. A.; Hatem, M.; Leighton,  M. J.; and Ruml, W. 2012. Implementing fast heuristic search code. In SOCS.
  \bibitem{BHLR12}Ethan Andrew Burns, Matthew Hatem, Michael J Leighton, and Wheeler Ruml. Implementing fast heuristic search code. In SOCS, 2012.
  \bibitem{Kor85}Korf, R. E. 1985. Depth-first iterativedeepening: An optimal admissible tree search. Artificial intelligence 27(1):97-109.
  \bibitem{KF02}Korf, R. E., and Felner, A. 2002. Disjoint pattern database heuristics. Artificial intelligence 134(1):9-22.
  \bibitem{HNR68}Peter E Hart, Nils J Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE transactions on Systems Science and Cybernetics, Vol. 4, No. 2, pp. 100-107, 1968. 
  \bibitem{Rus92}Russell, S. 1992. Efficient memory-bounded search methods. In Neumann, B. Proceedings of the 10th European Conference on Artificial intelligence. Vienna, Austria: John Wiley \& Sons, New York, NY. pp. 1–5.

\end{thebibliography}
%---------------------------------必須エリア-------------------------------%
\end{document}


%----------------------------ファイルはここまで----------------------------%
